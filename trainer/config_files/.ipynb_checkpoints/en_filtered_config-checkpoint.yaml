number: '0123456789'
symbol: "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ €"
lang_char: 'None' #'ABCDEFGHIJKLMNOƟPQRSTUVWXYZabcdefghijklmnoɵpqrstuvwxyz'
experiment_name: 'en_sample'
train_data: 'all_data'
valid_data: 'all_data/gum_val' # debería ser un dataset de validación, no el de training
manualSeed: 1111
workers: 6
batch_size: 32 #32
num_iter: 300 #300000
valInterval: 10 #20000
saved_model: '' #'saved_models/en_sample/None-VGG-BiLSTM-CTC-en_sample.pth'
FT: False
optim: False # default is Adadelta
lr: 1.
beta1: 0.9
rho: 0.95
eps: 0.00000001
grad_clip: 5
#Data processing
select_data: 'gum_train' # Aqui se elige que dataset se va a usar para entrenar. normalmente se meten en carpetas dentro de /all_data
batch_ratio: '1' 
total_data_usage_ratio: 1.0
batch_max_length: 400 #34 
imgH: 64
imgW: 600
rgb: False
contrast_adjust: False
sensitive: True
PAD: True
contrast_adjust: 0.0
data_filtering_off: False
# Model Architecture
Transformation: 'None'
FeatureExtraction: 'VGG'
SequenceModeling: 'BiLSTM'
Prediction: 'CTC'
num_fiducial: 20
input_channel: 1
output_channel: 256
hidden_size: 256
decode: 'greedy'
new_prediction: False
freeze_FeatureFxtraction: False
freeze_SequenceModeling: False